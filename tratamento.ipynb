{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98a04669-0265-46bf-9e54-b05272d27514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c908120-771b-4806-91d2-c33d848f960d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Dados meteorológicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fe98efe-79ca-4302-81b1-c6bff12434b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_met1 = pd.read_csv('./dados/met1.csv', sep=';', decimal=',') #Lendo a planílha 1 01/01/2019 - 30/06/2019\n",
    "df_met2 = pd.read_csv('./dados/met2.csv', sep=';', decimal=',') #Lendo a planilha 2 01/07/2019 - 31/12/2019\n",
    "df_met3 = pd.read_csv('./dados/met3.csv', sep=';', decimal=',') #Lendo a planilha 3 01/01/2020 - 06/01/2020\n",
    "df_met4 = pd.read_csv('./dados/met4.csv', sep=';', decimal=',') #Lendo a planílha 4 30/10/2021 - 30/04/2012\n",
    "df_met5 = pd.read_csv('./dados/met5.csv', sep=';', decimal=',') #Lendo a planilha 5 01/05/2022 - 30/07/2022\n",
    "\n",
    "df_met3 = df_met3.iloc[0:123] #Excluindo os valores excedentes do dia 06/01/2020 (A partir da linha 123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c690bb28-3a97-40d5-aba4-599a427103ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_met_1 = pd.concat([df_met1, df_met2, df_met3], ignore_index=True) #Concatenando os 3 dataframes\n",
    "\n",
    "date_range = pd.date_range(start = '1/1/2019', end='1/6/2020 3:00:00', freq='H', inclusive='left', tz = 'utc') #Criando um range com as datas\n",
    "date_range = date_range.tz_convert('Etc/GMT+3') #Convertendo de UTC para UTC-3\n",
    "date_range = date_range.tz_localize(tz = None) #Fazendo com que o range esqueça a timezone\n",
    "\n",
    "df_date = pd.DataFrame(date_range, columns=['Data e Hora']) #Transformando o range em um DataFrame29\n",
    "df_date = pd.to_datetime(df_date['Data e Hora']) #Transformando Data e Hora em um objeto DateTime\n",
    "\n",
    "df_met_1['Data e Hora'] = df_date #Incluindo a coluna Data e Hora no dataframe\n",
    "df_met_1.drop(['Data', 'Hora (UTC)'], axis = 1, inplace = True) #Excluindo as colunas 'Data' e 'Hora (UTC)' \n",
    "df_met_1 = df_met_1.iloc[123:] #Excluindo os dados de 01/01/2019 - 05/01/2019\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28eb8e31-30a1-48eb-a528-73bb3be4831d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_met5 = df_met5.iloc[0:2187] #Excluindo os valores excedentes do dia 30/07/2022 (A partir da linha 2187)\n",
    "\n",
    "df_met_2 = pd.concat([df_met4, df_met5], ignore_index=True) #Concatenando os 2 dataframes\n",
    "\n",
    "\n",
    "date_range = pd.date_range(start = '10/30/2021', end='7/30/2022 3:00:00', freq='H', inclusive='left', tz = 'utc') #Criando um range com as datas\n",
    "date_range = date_range.tz_convert('Etc/GMT+3') #Convertendo de UTC para UTC-3\n",
    "date_range = date_range.tz_localize(tz = None) #Fazendo com que o range esqueça a timezone\n",
    "\n",
    "df_date = pd.DataFrame(date_range, columns=['Data e Hora']) #Transformando o range em um DataFrame29\n",
    "df_date = pd.to_datetime(df_date['Data e Hora']) #Transformando Data e Hora em um objeto DateTime\n",
    "\n",
    "df_met_2['Data e Hora'] = df_date #Incluindo a coluna Data e Hora no dataframe\n",
    "df_met_2.drop(['Data', 'Hora (UTC)'], axis = 1, inplace = True) #Excluindo as colunas 'Data' e 'Hora (UTC)' \n",
    "df_met_2 = df_met_2.iloc[3:] #Excluindo os dados excedentes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa61f76b-eea0-4aa4-9640-09bffed8d1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_met = pd.concat([df_met_1, df_met_2], ignore_index=True) #Concatenando os 3 dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a07e54c8-90f1-4437-97cd-05b2c3c3d75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_met.to_csv(path_or_buf='./dados/dados_met.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e344d7-bb29-4df6-85b8-50d85e248597",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Dados de Potência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b73f021-90b0-43dc-bf10-089bb3f2a234",
   "metadata": {},
   "outputs": [],
   "source": [
    "#LENDO OS DADOS#\n",
    "\n",
    "df_pot1 = pd.read_excel('./dados/potencia1.xlsx', decimal=',') #Lendo o arquivo de dados de geração\n",
    "df_pot2 = pd.read_excel('./dados/potencia2.xlsx', decimal=',') #Lendo o arquivo de dados de geração\n",
    "df_pot3 = pd.read_excel('./dados/potencia3.xlsx', decimal=',') #Lendo o arquivo de dados de geração\n",
    "df_pot4 = pd.read_excel('./dados/potencia4.xlsx', decimal=',') #Lendo o arquivo de dados de geração\n",
    "df_pot5 = pd.read_excel('./dados/potencia5.xlsx', decimal=',') #Lendo o arquivo de dados de geração\n",
    "df_pot6 = pd.read_excel('./dados/potencia6.xlsx', decimal=',') #Lendo o arquivo de dados de geração\n",
    "df_pot7 = pd.read_excel('./dados/potencia7.xlsx', decimal=',') #Lendo o arquivo de dados de geração\n",
    "df_pot8 = pd.read_excel('./dados/potencia8.xlsx', decimal=',') #Lendo o arquivo de dados de geração\n",
    "df_pot9 = pd.read_excel('./dados/potencia9.xlsx', decimal=',') #Lendo o arquivo de dados de geração\n",
    "df_pot10 = pd.read_excel('./dados/potencia10.xlsx', decimal=',') #Lendo o arquivo de dados de geração\n",
    "df_pot11 = pd.read_excel('./dados/potencia11.xlsx', decimal=',') #Lendo o arquivo de dados de geração\n",
    "df_pot12 = pd.read_excel('./dados/potencia12.xlsx', decimal=',') #Lendo o arquivo de dados de geração\n",
    "\n",
    "df_pot_1 = pd.concat([df_pot1, df_pot2, df_pot3, df_pot4, df_pot5, df_pot6, df_pot7], ignore_index=True) #Concatenando os dataframes\n",
    "\n",
    "df_pot_1 = df_pot_1[['Data e Hora', 'Potência CA (W)']] #Selecionando as colunas\n",
    "\n",
    "df_pot_1['Data e Hora'] = pd.to_datetime(df_pot_1['Data e Hora'], dayfirst=True) #Transformando a coluna Data e Hora \n",
    "#em um objeto do tipo DateTime\n",
    "df_pot_1 = df_pot_1.resample('H', on='Data e Hora').mean() #Calculando a média de Potência gerada a cada hora\n",
    "\n",
    "date_range = pd.date_range(start = '1/6/2019', end='1/6/2020', freq='H', inclusive='left') #Criando um range com as datas\n",
    "\n",
    "df_date = pd.DataFrame(date_range, columns=['Data e Hora']) #Transformando o range em um DataFrame\n",
    "df_date = pd.to_datetime(df_date['Data e Hora']) #Transformando Data e Hora em um objeto DateTime\n",
    "\n",
    "df_pot_1 = pd.merge(df_date, df_pot_1, on='Data e Hora', how='inner') #Fazendo um merge entre os dois DataFrames de datas \n",
    "#e criando df_pot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f681bc55-d535-481a-8109-ab8dcad399cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/domingos/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3398: UserWarning: Parsing '30/10/2021' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "df_pot_2 = pd.concat([df_pot8, df_pot9, df_pot10, df_pot11, df_pot12], ignore_index=True)\n",
    "\n",
    "df_pot_2 = df_pot_2[['Data e Hora', 'Potência CA (W)']] #Selecionando as colunas\n",
    "\n",
    "df_pot_2['Data e Hora'] = pd.to_datetime(df_pot_2['Data e Hora'], dayfirst=True) #Transformando a coluna Data e Hora \n",
    "#em um objeto do tipo DateTime\n",
    "df_pot_2 = df_pot_2.resample('H', on='Data e Hora').mean() #Calculando a média de Potência gerada a cada hora\n",
    "\n",
    "date_range = pd.date_range(start = '30/10/2021', end='30/7/2022', freq='H', inclusive='left') #Criando um range com as datas\n",
    "\n",
    "df_date = pd.DataFrame(date_range, columns=['Data e Hora']) #Transformando o range em um DataFrame\n",
    "df_date = pd.to_datetime(df_date['Data e Hora']) #Transformando Data e Hora em um objeto DateTime\n",
    "\n",
    "df_pot_2 = pd.merge(df_date, df_pot_2, on='Data e Hora', how='inner') #Fazendo um merge entre os dois DataFrames de datas \n",
    "#e criando df_pot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6b2f683-d000-451d-884c-17686cb23989",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame(pd.date_range(start = '1/6/2019 00:00:00', end='1/6/2019 05:00:00', freq='H', inclusive='left'),\n",
    "                         columns=['Data e Hora']) #Criando dados da madrugada do dia 06/01/2019\n",
    "\n",
    "df_2 = pd.DataFrame(pd.date_range(start = '1/5/2020 20:00:00', end='1/5/2020 23:00:00', freq='H'),\n",
    "                         columns=['Data e Hora']) #Criando dados da noite do dia 05/01/2020\n",
    "\n",
    "df_1['Potência CA (W)'] = [0, 0, 0, 0, 0] #Preenchendo os dados de potência\n",
    "df_2['Potência CA (W)'] = [0, 0, 0, 0] #Preenchendo os dados de potência\n",
    "\n",
    "df_pot_1 = pd.concat([df_1, df_pot_1, df_2]) #Contatenando os 3 dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1085b732-b081-49d9-bfed-af1f822fe5da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame(pd.date_range(start = '30/10/2021 00:00:00', end='30/10/2021 05:00:00', freq='H', inclusive='left'),\n",
    "                         columns=['Data e Hora']) #Criando dados da madrugada do dia 30/10/2021\n",
    "\n",
    "df_1['Potência CA (W)'] = [0, 0, 0, 0, 0] #Preenchendo os dados de potência\n",
    "\n",
    "df_pot_2 = pd.concat([df_1, df_pot_2]) #Contatenando os 3 dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45d209b0-012b-464e-af5b-3d13da92bbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pot = pd.concat([df_pot_1, df_pot_2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "674c289e-1a66-4d2f-b140-9fbdab5f0766",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pot.to_csv(path_or_buf='./dados/dados_pot.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0eeaf3-0b5d-45a6-bafc-d249b479a94d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Unindo os dois DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73c4064f-a068-46aa-9a2e-49a6a0ef6aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df_met, df_pot, how='inner', on='Data e Hora') #Fazendo o merge dos dois dataframes\n",
    "\n",
    "df['Data e Hora'] = pd.to_datetime(df['Data e Hora']) #Transformando a coluna Data e Hora em DateTime\n",
    "df['Hora'] = df['Data e Hora'].dt.hour #Criando uma coluna com as horas\n",
    "df['Mês'] = df['Data e Hora'].dt.month #Criando uma coluna com os meses\n",
    "\n",
    "df = df[['Data e Hora', 'Hora', 'Mês', 'Temp. Ins. (C)', 'Temp. Max. (C)', 'Temp. Min. (C)', 'Umi. Ins. (%)', \n",
    "         'Umi. Max. (%)', 'Umi. Min. (%)', 'Pto Orvalho Ins. (C)', 'Pto Orvalho Max. (C)', 'Pto Orvalho Min. (C)', \n",
    "         'Pressao Ins. (hPa)', 'Pressao Max. (hPa)', 'Pressao Min. (hPa)', 'Vel. Vento (m/s)', 'Dir. Vento (m/s)', \n",
    "         'Raj. Vento (m/s)', 'Radiacao (KJ/m²)', 'Chuva (mm)', 'Potência CA (W)']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40fd1f55-a4fe-4697-88a7-687aba2ea60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(path_or_buf='./dados/dados_teste.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d885ca-eadd-4345-8dfd-d2df76782bdf",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Tratamento geral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "992dba0c-77d9-4ded-86a1-0aacf0bb73f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['Radiacao (KJ/m²)']!=0]\n",
    "df = df[df['Potência CA (W)']!=0]\n",
    "\n",
    "df.dropna(subset=['Radiacao (KJ/m²)'], inplace=True)\n",
    "df.dropna(subset=['Potência CA (W)'], inplace=True) #Excluindo todas as amostras em que a Potência é NaN\n",
    "\n",
    "df.fillna(method='bfill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c58c4964-bdbb-4841-b2c7-a48ca04df318",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(path_or_buf='./dados/dados.csv', index=False) #Expostando o dataframe para um arquivo .csv externo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0d555105557f66a9a45792b632724fc3e2f2f64eea2ec00e88d317940673588"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
